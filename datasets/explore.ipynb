{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image\n",
    "import numpy as np\n",
    "import glob\n",
    "import imageio.v3 as iio\n",
    "import dlib\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./fer2013\"):\n",
    "    # download_fer2013()\n",
    "    pass\n",
    "\n",
    "def train_path(category, filename=\"*\", processed=False):\n",
    "    if processed: \n",
    "        return f\"./fer2013/train_processed/{category}/{filename}.jpg\"\n",
    "    return f\"./fer2013/train/{category}/{filename}.jpg\"\n",
    "\n",
    "def test_path(category, filename=\"*\", processed=False):\n",
    "    if processed: \n",
    "        return f\"./fer2013/test_processed/{category}/{filename}.jpg\"\n",
    "    return f\"./fer2013/test/{category}/{filename}.jpg\"\n",
    "\n",
    "emotions = [\n",
    "    \"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"\n",
    "]\n",
    "\n",
    "if not os.path.exists(\"./fer2013/test_processed\"): \n",
    "    os.system(\"mkdir ./fer2013/test_processed\")\n",
    "    for emotion in emotions: \n",
    "        os.system(f\"mkdir ./fer2013/test_processed/{emotion}\")\n",
    "if not os.path.exists(\"./fer2013/train_processed\"):\n",
    "    os.system(\"mkdir ./fer2013/train_processed\")\n",
    "    for emotion in emotions: \n",
    "        os.system(f\"mkdir ./fer2013/train_processed/{emotion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry 2750 3995 i.e., 68.84%\n",
      "disgust 340 436 i.e., 77.98%\n",
      "fear 2542 4097 i.e., 62.05%\n",
      "happy 5620 7215 i.e., 77.89%\n",
      "neutral 3728 4965 i.e., 75.09%\n",
      "sad 2663 4830 i.e., 55.13%\n",
      "surprise 2358 3171 i.e., 74.36%\n"
     ]
    }
   ],
   "source": [
    "# train set percentages\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "for emotion in emotions:\n",
    "    total, withface = 0, 0\n",
    "    for p in glob.glob(train_path(emotion)):\n",
    "        im = iio.imread(p)\n",
    "        bbox = detector(im, 1)\n",
    "        if bbox:\n",
    "            withface += 1\n",
    "        total += 1\n",
    "\n",
    "    print(emotion, withface, total, f\"i.e., {100 * withface / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3995/3995 [00:11<00:00, 356.43it/s]\n",
      "100%|██████████| 436/436 [00:01<00:00, 367.51it/s]\n",
      "100%|██████████| 4097/4097 [00:11<00:00, 363.41it/s]\n",
      "100%|██████████| 7215/7215 [00:22<00:00, 325.09it/s]\n",
      "100%|██████████| 4965/4965 [00:15<00:00, 314.80it/s]\n",
      "100%|██████████| 4830/4830 [00:13<00:00, 350.09it/s]\n",
      "100%|██████████| 3171/3171 [00:09<00:00, 322.41it/s]\n",
      "100%|██████████| 958/958 [00:02<00:00, 321.64it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 339.01it/s]\n",
      "100%|██████████| 1024/1024 [00:02<00:00, 347.05it/s]\n",
      "100%|██████████| 1774/1774 [00:05<00:00, 319.73it/s]\n",
      "100%|██████████| 1233/1233 [00:03<00:00, 335.83it/s]\n",
      "100%|██████████| 1247/1247 [00:03<00:00, 365.92it/s]\n",
      "100%|██████████| 831/831 [00:02<00:00, 349.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# do preprocess for training data, testing data\n",
    "fullsize, halfsize, quadsize = 48, 48 // 2, 48 // 4\n",
    "\n",
    "def do_preprocess():\n",
    "    for pathfunc in [train_path, test_path]:\n",
    "        for emotion in emotions: \n",
    "            for p in tqdm(glob.glob(pathfunc(emotion))):\n",
    "                im = iio.imread(p)\n",
    "                bboxes = detector(im, 1)\n",
    "                for bbox in bboxes:\n",
    "                    top = max(0, bbox.top())\n",
    "                    bottom = min(bbox.bottom(), fullsize)\n",
    "                    left = max(0, bbox.left())\n",
    "                    right = min(bbox.right(), fullsize)\n",
    "\n",
    "                    new_center = (top + bottom) // 2 - 6\n",
    "                    if new_center < quadsize: \n",
    "                        top = 0\n",
    "                        bottom = halfsize\n",
    "                    elif new_center > fullsize - quadsize: \n",
    "                        top = fullsize - quadsize\n",
    "                        bottom = quadsize\n",
    "                    else:\n",
    "                        top = new_center - quadsize\n",
    "                        bottom = new_center + quadsize\n",
    "                    im = im[top:bottom, :]\n",
    "\n",
    "                    save_filename = \"pd_\" + p.strip().split(\"/\")[-1][:-4]\n",
    "                    matplotlib.image.imsave(\n",
    "                        pathfunc(emotion, save_filename, processed=True), \n",
    "                        im\n",
    "                    )\n",
    "\n",
    "do_preprocess()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece219",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
